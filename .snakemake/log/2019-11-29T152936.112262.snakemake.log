Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 10
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	4	Build_Exonerate_Alignment
	4	Build_Spaln_Alignment
	3	Filter_Out_Useless_Regions
	3	Find_Candidates
	1	Join_ProDA_Results
	4	Merge_Results
	4	Retrieve_Sequence_Similarities
	4	Retrieve_Sequence_With_Highest_Similarity
	1	Visualize_Discarded_Results
	1	Visualize_Retained_Results
	1	finish
	30

[Fri Nov 29 15:29:36 2019]
rule Build_Exonerate_Alignment:
    input: data/queries/beta_tubulin2.faa, matches/gpe/beta_tubulin2.fna
    output: exonerate/gpe/beta_tubulin2.faa
    log: log/exonerate/gpe/beta_tubulin2.log
    jobid: 22
    wildcards: subject=gpe, query=beta_tubulin2
    threads: 10

[Fri Nov 29 15:30:05 2019]
Finished job 22.
1 of 30 steps (3%) done

[Fri Nov 29 15:30:05 2019]
rule Build_Spaln_Alignment:
    input: data/queries/beta_tubulin2.faa, matches/gpe/beta_tubulin2.fna
    output: spaln/gpe/beta_tubulin2.faa, spaln/gpe/beta_tubulin2.sp
    log: log/spaln/gpe/beta_tubulin2.log
    jobid: 23
    wildcards: subject=gpe, query=beta_tubulin2
    threads: 10

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/valentin/git/ProDA/.snakemake/log/2019-11-29T152936.112262.snakemake.log
