Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 10
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	3	Build_Exonerate_Alignment
	4	Build_Spaln_Alignment
	3	Filter_Out_Useless_Regions
	3	Find_Candidates
	1	Join_ProDA_Results
	4	Merge_Results
	4	Retrieve_Sequence_Similarities
	4	Retrieve_Sequence_With_Highest_Similarity
	1	Visualize_Discarded_Results
	1	Visualize_Retained_Results
	1	finish
	29

[Fri Nov 29 15:32:29 2019]
rule Build_Spaln_Alignment:
    input: data/queries/beta_tubulin2.faa, matches/gpe/beta_tubulin2.fna
    output: spaln/gpe/beta_tubulin2.faa, spaln/gpe/beta_tubulin2.sp
    log: log/spaln/gpe/beta_tubulin2.log
    jobid: 23
    wildcards: subject=gpe, query=beta_tubulin2
    threads: 10

Removing temporary output file spaln/gpe/beta_tubulin2.sp.
[Fri Nov 29 15:32:42 2019]
Finished job 23.
1 of 29 steps (3%) done

[Fri Nov 29 15:32:42 2019]
rule Merge_Results:
    input: exonerate/gpe/beta_tubulin2.faa, spaln/gpe/beta_tubulin2.faa
    output: cd_hit/gpe/beta_tubulin2_merged.faa, cd_hit/gpe/beta_tubulin2_joined.faa
    log: log/cd_hit/gpe/beta_tubulin2.log
    jobid: 15
    wildcards: subject=gpe, query=beta_tubulin2
    threads: 10

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/valentin/git/ProDA/.snakemake/log/2019-11-29T153229.466890.snakemake.log
