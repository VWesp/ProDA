Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	matcher
	1	test
	3

[Tue Nov 19 10:04:40 2019]
rule matcher:
    input: ../data/subjects/csp.fasta, ../data/subjects/gonium.fasta, blast_results/csp/actin.hit, blast_results/csp/beta_tubulin2.hit, blast_results/gonium/actin.hit, blast_results/gonium/beta_tubulin2.hit
    output: temp/scripts.txt
    jobid: 2

/home/valentin/anaconda3/bin/python3.6 /home/valentin/git/ProDA/.snakemake/scripts/tmp584u16pu.contig_query_matcher.py
[Tue Nov 19 10:04:43 2019]
Finished job 2.
1 of 3 steps (33%) done

[Tue Nov 19 10:04:43 2019]
rule test:
    input: temp/scripts.txt
    output: temp/end.txt
    jobid: 1

touch temp/end.txt
[Tue Nov 19 10:04:43 2019]
Finished job 1.
2 of 3 steps (67%) done

[Tue Nov 19 10:04:43 2019]
localrule all:
    input: temp/end.txt
    jobid: 0

[Tue Nov 19 10:04:43 2019]
Finished job 0.
3 of 3 steps (100%) done
Complete log: /home/valentin/git/ProDA/.snakemake/log/2019-11-19T100440.888724.snakemake.log
