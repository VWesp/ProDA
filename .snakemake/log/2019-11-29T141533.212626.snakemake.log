Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 10
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	4	Build_Exonerate_Alignment
	3	Build_Spaln_Alignment
	3	Filter_Out_Useless_Regions
	3	Find_Candidates
	1	Join_ProDA_Results
	4	Merge_Results
	4	Retrieve_Sequence_Similarities
	4	Retrieve_Sequence_With_Highest_Similarity
	1	Visualize_Discarded_Results
	1	Visualize_Retained_Results
	1	finish
	29

[Fri Nov 29 14:15:33 2019]
rule Build_Exonerate_Alignment:
    input: data/queries/beta_tubulin2.faa, matches/gpe/beta_tubulin2.fna
    output: exonerate/gpe/beta_tubulin2.fna, exonerate/gpe/beta_tubulin2.faa
    log: log/exonerate/gpe/beta_tubulin2.log
    jobid: 22
    wildcards: subject=gpe, query=beta_tubulin2
    threads: 10

Terminating processes on user request, this might take some time.
Cancelling snakemake on user request.
