Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	Join_Mapping_Results
	1	Join_ProDA_Results
	2	Map_Discarded_Results
	2	Map_Retained_Results
	1	Visualize_Discarded_Results
	1	Visualize_Retained_Results
	1	finish
	9

[Fri Nov 29 11:30:13 2019]
rule Join_ProDA_Results:
    input: best_hit/csp/actin.tsv, best_hit/csp/beta_tubulin2.tsv, best_hit/gpe/actin.tsv, best_hit/gpe/beta_tubulin2.tsv
    output: results/retained/proda_temp.tsv, results/discarded/proda_temp.tsv
    log: log/results/results.log
    jobid: 8

[Fri Nov 29 11:30:14 2019]
Finished job 8.
1 of 9 steps (11%) done

[Fri Nov 29 11:30:14 2019]
rule Map_Retained_Results:
    input: data/subjects/gpe.fna, results/retained/proda_temp.tsv
    output: results/retained/proda_gpe.tsv
    jobid: 5
    wildcards: subject=gpe

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/valentin/git/ProDA/.snakemake/log/2019-11-29T113013.434337.snakemake.log
